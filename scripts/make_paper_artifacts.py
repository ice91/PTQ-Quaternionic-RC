#!/usr/bin/env python3
# scripts/make_paper_artifacts.py (enhanced)
from __future__ import annotations
import argparse, json
from pathlib import Path
import shutil
import yaml
import pandas as pd

from ptquat.fit_global import run as run_fit_direct
from ptquat import experiments as EXP

def _ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)

def _run_fit(model: str, tidy_csv: Path, outdir: Path,
             likelihood: str, fast: bool, prior: str = "galaxies-only") -> Path:
    _ensure_dir(outdir)
    steps = "200" if fast else "6000"
    nwalk = "2x" if fast else "4x"
    argv = [
        f"--data-path={tidy_csv}",
        f"--outdir={outdir}",
        f"--model={model}",
        f"--likelihood={likelihood}",
        f"--steps={steps}",
        f"--nwalkers={nwalk}",
        f"--seed=42",
        f"--prior={prior}",
        f"--sigma-sys=4.0",
    ]
    print("+ ptquat.fit_global.run", " ".join(argv), flush=True)
    run_fit_direct(argv)
    gpath = outdir / "global_summary.yaml"
    if not gpath.exists():
        raise RuntimeError(f"Fit finished but {gpath} missing.")
    return gpath

def _copy_if_exists(src: Path, dst: Path) -> None:
    if src.exists():
        shutil.copyfile(src, dst)

def run_diagnostics_for(results_dir: Path,
                        tidy_csv: Path,
                        figdir: Path,
                        omega_lambda: float,
                        eta: float,
                        nbins: int) -> dict:
    # plateau
    _, plateau_png = EXP.residual_plateau(str(results_dir), str(tidy_csv), nbins=nbins, out_prefix="plateau")
    # ppc
    _ = EXP.ppc_check(str(results_dir), str(tidy_csv), out_prefix="ppc")

    # --- kappa profiles: eps_norm=fit & cos 各一 ---
    # cos
    _, kprof_cos = EXP.kappa_radius_resolved(
        results_dir=str(results_dir), data_path=str(tidy_csv),
        eta=eta, omega_lambda=omega_lambda, nbins=nbins, min_per_bin=10,
        x_kind="r_over_Rd", eps_norm="cos", out_prefix="kappa_profile_cos"
    )
    fit_cos = EXP.kappa_two_param_fit(str(results_dir), prefix="kappa_profile_cos",
                                      eps_norm="cos", omega_lambda=omega_lambda)
    boot_cos = EXP.kappa_two_param_bootstrap(str(results_dir), prefix="kappa_profile_cos",
                                             eps_norm="cos", omega_lambda=omega_lambda,
                                             n_boot=2000, min_per_bin=10, seed=42)
    # fit
    _, kprof_fit = EXP.kappa_radius_resolved(
        results_dir=str(results_dir), data_path=str(tidy_csv),
        eta=eta, nbins=nbins, min_per_bin=10,
        x_kind="r_over_Rd", eps_norm="fit", out_prefix="kappa_profile_fit"
    )
    fit_fit = EXP.kappa_two_param_fit(str(results_dir), prefix="kappa_profile_fit",
                                      eps_norm="fit", omega_lambda=omega_lambda)
    boot_fit = EXP.kappa_two_param_bootstrap(str(results_dir), prefix="kappa_profile_fit",
                                             eps_norm="fit", omega_lambda=omega_lambda,
                                             n_boot=2000, min_per_bin=10, seed=99)

    # kappa-gal（主文可備用）
    _ = EXP.kappa_per_galaxy(results_dir=str(results_dir), data_path=str(tidy_csv),
                             eta=eta, frac_vmax=0.9, nsamp=300, omega_lambda=omega_lambda,
                             out_prefix="kappa_gal")

    # closure
    _ = EXP.closure_test(str(results_dir), omega_lambda=omega_lambda)

    # 收圖
    _ensure_dir(figdir)
    _copy_if_exists(plateau_png, figdir / f"plateau_{results_dir.name}.png")
    _copy_if_exists(kprof_cos,  figdir / f"kappa_profile_cos_{results_dir.name}.png")
    _copy_if_exists(kprof_fit,  figdir / f"kappa_profile_fit_{results_dir.name}.png")
    _copy_if_exists(results_dir / "kappa_gal.png", figdir / f"kappa_gal_{results_dir.name}.png")

    # 產生 LaTeX 巨集
    tex = figdir / "values.tex"
    def _pm(q): 
        return f"{q['p50']:.4f}_{{-{q['p50']-q['p16']:.4f}}}^{{+{q['p84']-q['p50']:.4f}}}"
    with open(tex, "w") as f:
        f.write("% auto-generated by make_paper_artifacts.py\n")
        f.write(f"\\newcommand{{\\etaHatCos}}{{{boot_cos['eta_hat']['p50']:.5f}}}\n")
        f.write(f"\\newcommand{{\\etaHatCosCI}}{{{_pm(boot_cos['eta_hat'])}}}\n")
        f.write(f"\\newcommand{{\\BCos}}{{{boot_cos['B_cos']['p50']:.5f}}}\n")
        f.write(f"\\newcommand{{\\BCosCI}}{{{_pm(boot_cos['B_cos'])}}}\n")
        f.write(f"\\newcommand{{\\EtaFromFit}}{{{boot_fit['eta_hat']['p50']:.5f}}}\n")
        f.write(f"\\newcommand{{\\EtaFromFitCI}}{{{_pm(boot_fit['eta_hat'])}}}\n")
    print(f"[make] LaTeX macros -> {tex}")

    return dict(cos=fit_cos, fit=fit_fit)

def build_compare_csv(run_root: Path, out_csv: Path, models: list[str], like: str) -> pd.DataFrame:
    rows = []
    for m in models:
        rdir = run_root / f"{m}_{like}"
        gpath = rdir / "global_summary.yaml"
        if not gpath.exists(): 
            print(f"[make][warn] skip {m}: {gpath} not found", flush=True); continue
        y = yaml.safe_load(gpath.read_text())
        rows.append(dict(
            model=y.get("model", m),
            likelihood=y.get("likelihood", like),
            AIC_full=y.get("AIC_full"),
            BIC_full=y.get("BIC_full"),
            chi2_total=y.get("chi2_total"),
            k_parameters=y.get("k_parameters"),
            N_total=y.get("N_total"),
            outdir=str(rdir)
        ))
    df = pd.DataFrame(rows).sort_values("AIC_full")
    _ensure_dir(out_csv.parent)
    df.to_csv(out_csv, index=False)
    return df

def parse_args():
    import argparse
    ap = argparse.ArgumentParser(description="Build artifacts: fits, diagnostics, AB-fit+bootstrap, model-compare, TeX macros.")
    ap.add_argument("--data", required=True)
    ap.add_argument("--out", required=True)
    ap.add_argument("--figdir", required=True)
    ap.add_argument("--models", nargs="+", required=True)
    ap.add_argument("--likelihood", choices=["gauss","t"], default="gauss")
    ap.add_argument("--fast", action="store_true")
    ap.add_argument("--omega-lambda", type=float, default=0.685)
    ap.add_argument("--eta", type=float, default=0.15)
    ap.add_argument("--nbins", type=int, default=24)
    return ap.parse_args()

def main():
    args = parse_args()
    tidy_csv = Path(args.data)
    run_root = Path(args.out); _ensure_dir(run_root)
    figdir   = Path(args.figdir); _ensure_dir(figdir)
    # 1) fits
    results_dirs = {}
    for m in args.models:
        outdir = run_root / f"{m}_{args.likelihood}"
        _run_fit(model=m, tidy_csv=tidy_csv, outdir=outdir, likelihood=args.likelihood, fast=args.fast)
        results_dirs[m] = outdir
    # 2) diagnostics（優先 ptq-screen）
    target = "ptq-screen" if "ptq-screen" in results_dirs else list(results_dirs.keys())[-1]
    _ = run_diagnostics_for(results_dirs[target], tidy_csv, figdir, omega_lambda=args.omega_lambda, eta=args.eta, nbins=args.nbins)
    # 3) model compare
    cmp_csv = run_root / "ejpc_model_compare.csv"
    df = build_compare_csv(run_root, cmp_csv, list(results_dirs.keys()), args.likelihood)
    print(df.to_string(index=False))
    print(f"\n[make] Compare CSV -> {cmp_csv}")
    print(f"[make] Figures -> {figdir}")

if __name__ == "__main__":
    main()
